name: Image Security Pipeline

on:
  push:
    branches:
      - main  

jobs:
  scan:
    runs-on: ubuntu-latest


    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Scipt to Download and install Trivy
      run: |
        curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin v0.45.1

    - name: Create trivy-reports directory
      run: |
        mkdir -p trivy-reports
      shell: bash

    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.11.3

    - name: Run Python script for version tags/dates
      run: |
        pip install requests
        chmod +x Python_scripts/main.py
        python Python_scripts/main.py  # Replace with the actual name of your Python script


    - name: Open and extract data
      run: | 
        file_path="version_dict_file.txt"
        if [ -f "$file_path" ]; then
        # Iterate through each line in the file
        while IFS= read -r line; do
          # Print the current line (You can replace this with your processing logic)
          echo "Line: $line"
          
          # Example: Split the line into key and value
          IFS=":" read -r key value <<< "$line"
          echo "Key: $key, Value: $value"

          for item in "$value"; do
            echo "Item_is: $item"
          done
        done < "$file_path"
        else
          echo "File not found: $file_path"
        fi
      shell: bash

    # - name: Scan images and generate reports
    #   run: |
    #     # Define the list of image names you want to scan
    #     images=("alpine:latest" "nginx:latest" "ubuntu:latest" "python:latest" "redis:latest" "postgres:latest" "node:latest" "httpd:latest" "memcached:latest" "mongo:latest" "mysql:latest" "traefik:latest" "mariadb:latest" "docker:latest" "rabbitmq:latest" "golang:latest" "wordpress:latest" "php:latest" "sonarqube:latest" "ruby:latest" "haproxy:latest" "tomcat:latest" "kong:latest" "neo4j:latest")
    #     current_date=$(date +'%Y-%m-%d')
    #     for image in "${images[@]}"; do
    #       sanitized_name="${image//:/_}"
    #       echo "Scanning $image"
    #       trivy image -f json -o "trivy-reports/$sanitized_name.json" "$image"
    #       jq 'del(.Metadata.DiffIDs)' "trivy-reports/$sanitized_name.json" > "trivy-reports/$sanitized_name-no-diffid.json" && mv "trivy-reports/$sanitized_name-no-diffid.json" "trivy-reports/$sanitized_name.json"

    #       # docker inspect "$image" > "$json_file"


    #       # jq -c '.' "trivy-reports/$sanitized_name.json" > "trivy-reports/$sanitized_name.ndjson" && mv "trivy-reports/$sanitized_name.ndjson" "trivy-reports/$sanitized_name.json"

    #     done
    #   shell: bash
    
  
    - name: Upload Trivy Reports
      uses: actions/upload-artifact@v2
      with:
        name: trivy-reports
        path: trivy-reports

    
    - name: Set up AWS CLI
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws configure set region eu-north-1
      shell: bash

    # - name: Install requests library
    #   run: pip install requests

    - name: Create csv directory
      run: mkdir -p csv-data
      shell: bash
    
    - name: Check if project_data.csv exists if not create
      run: |
        if aws s3 ls s3://imagereportbucket/data_folder/project_data.csv; then
          echo "File exists"
          aws s3 cp s3://imagereportbucket/data_folder/project_data.csv csv-data/
        else
          echo "File does not exist"
          echo "Creating project_data.csv"
          echo "Your data" > csv-data/project_data.csv  # Create your data file locally
          # aws s3 cp csv-data/project_data.csv s3://imagereportbucket/data_folder/  # Upload the file to S3
        fi

    # - name: Create csv directory
    #   run: mkdir -p txt_file_dir
    #   shell: bash
    
    
    # - name: Run Python script
    #   run: |
    #    pip install requests
    #    chmod +x Python_scripts/python_main.py
    #    python Python_scripts/python_main.py  # Replace with the actual name of your Python script


    # - name: Upload Trivy Reports to Amazon S3
    #   run: |
    #     # Define the S3 bucket and folder (prefix) where you want to upload the reports
    #     s3_bucket="imagereportbucket"
    #     current_date=$(date +'%Y-%m-%d')
    #     # Define the S3 prefix, including the current date
    #     s3_prefix="trivy-reports-${current_date}/"
  
    #     # Loop through the reports and upload them to S3
    #     for report in trivy-reports/*.json; do
    #       aws s3 cp "$report" "s3://$s3_bucket/$s3_prefix$(basename $report)"
    #       aws s3 cp csv-data/project_data.csv s3://imagereportbucket/data_folder/  # Upload the file to S3
    #     done
    #   shell: bash
      