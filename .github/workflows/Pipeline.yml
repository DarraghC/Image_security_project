name: Image Security Pipeline

on:
  push:
    branches:
      - main  # Adjust the branch as needed

jobs:
  scan:
    runs-on: ubuntu-latest

    # env:
    #   VERSION_DICT: '{"alpine": [], }'

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    # - name: Scipt to Download and install Trivy
    #   run: |
    #     curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin v0.45.1

    # - name: Create trivy-reports directory
    #   run: |
    #     mkdir -p trivy-reports
    #     mkdir -p trivy-version-reports
    #   shell: bash

    # - name: Define image names dictionary
    #   run: |
    #     images=("alpine" "nginx" "ubuntu" "python" "redis" "postgres" "node" "httpd" "memcached" "mongo" "mysql" "traefik" "mariadb" "docker" "rabbitmq" "golang" "wordpress" "php" "sonarqube" "ruby" "haproxy" "tomcat" "kong" "neo4j")

    #     # Create an associative array (dictionary) with image names as keys and empty arrays as values
    #     declare -A image_dict=()
    #     for image_name in "${images[@]}"; do
    #       image_dict["$image_name"]=()
    #     done
    
    #     # Print the dictionary for testing
    #     for key in "${!image_dict[@]}"; do
    #       echo "Key: $key, Value: ${image_dict[$key]}"
    #     done
    #   shell: bash

    # - name: Scan images and generate reports
    #   run: |
    #     # Define the list of image names you want to scan
    #     images=("alpine:latest" "nginx:latest" "ubuntu:latest" "python:latest" "redis:latest" "postgres:latest" "node:latest" "httpd:latest" "memcached:latest" "mongo:latest" "mysql:latest" "traefik:latest" "mariadb:latest" "docker:latest" "rabbitmq:latest" "golang:latest" "wordpress:latest" "php:latest" "sonarqube:latest" "ruby:latest" "haproxy:latest" "tomcat:latest" "kong:latest" "neo4j:latest")
    #     current_date=$(date +'%Y-%m-%d')
    #     for image in "${images[@]}"; do
    #       sanitized_name="${image//:/_}"
    #       echo "Scanning $image"
    #       trivy image -f json -o "trivy-reports/$sanitized_name.json" "$image"
    #       jq 'del(.Metadata.DiffIDs)' "trivy-reports/$sanitized_name.json" > "trivy-reports/$sanitized_name-no-diffid.json" && mv "trivy-reports/$sanitized_name-no-diffid.json" "trivy-reports/$sanitized_name.json"

    #       # docker inspect "$image" > "$json_file"


    #       # jq -c '.' "trivy-reports/$sanitized_name.json" > "trivy-reports/$sanitized_name.ndjson" && mv "trivy-reports/$sanitized_name.ndjson" "trivy-reports/$sanitized_name.json"

    #     done
    #   shell: bash
    
    # - name: Inspect Docker Images
    #   run: |
    #     # Iterate through the images array and perform docker inspect
    #     images=("alpine:latest" "nginx:latest" "ubuntu:latest" "python:latest" "redis:latest" "postgres:latest" "node:latest" "httpd:latest" "memcached:latest" "mongo:latest" "mysql:latest" "traefik:latest" "mariadb:latest" "docker:latest" "rabbitmq:latest" "golang:latest" "wordpress:latest" "php:latest" "sonarqube:latest" "ruby:latest" "haproxy:latest" "tomcat:latest" "kong:latest" "neo4j:latest")
    #     for image in "${images[@]}"; do
    #       # Define the JSON file path for the current image
    #       sanitized_name="${image//:/_}"
    #       json_file="trivy-version-reports/$sanitized_name-docker-inspect.json"

    #       # Perform docker inspect and save the output to the JSON file
    #       docker pull "$image"
    #       docker inspect "$image" > "$json_file"

    #       # You can optionally capture and process the output as needed
    #       # For example, if you want to extract specific information from the JSON
    #       # Example: image_id=$(jq -r '.[0].Id' "$json_file")

    #       echo "Docker inspect for $image completed, results saved to $json_file"
    #     done

    # - name: Upload Trivy Reports
    #   uses: actions/upload-artifact@v2
    #   with:
    #     name: trivy-repotrs
    #     path: trivy-reports

    
    # - name: Set up AWS CLI
    #   run: |
    #     aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
    #     aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    #     aws configure set region eu-north-1
    #   shell: bash

    # - name: Install requests library
    #   run: pip install requests

    # - name: Get Docker Hub Image Tags
    #   run: |
    #     # Define the Docker Hub repository and image name
    #     repository="library/alpine"  # Replace with your desired repository and image name

    #     # Use Docker Hub API to get tags
    #     tags_url="https://hub.docker.com/v2/repositories/${repository}/tags/"
    #     response=$(curl -s ${tags_url})

    #     # Parse JSON response to extract tags
    #     tags=$(echo ${response} | jq -r '.results[].name')

    #     # Print the tags
    #     echo "Tags for ${repository}:"
    #     echo "${tags}"
    #   env:
    #     DOCKER_LOGIN_USERNAME: ${{ secrets.DOCKER_LOGIN_USERNAME }}
    #     DOCKER_LOGIN_PASSWORD: ${{ secrets.DOCKER_LOGIN_PASSWORD }}

    # - name: Display Docker Tags
    #   run: |
    #     echo "Tags for Docker Hub image:"
    #     echo ${{ steps.get_docker_tags.outputs.tags }}

    # - name: Create csv directory
    #   run: mkdir -p csv-data
    #   shell: bash
    
    # - name: Check if project_data.csv exists if not create
    #   run: |
    #     if aws s3 ls s3://imagereportbucket/data_folder/project_data.csv; then
    #       echo "File exists"
    #       aws s3 cp s3://imagereportbucket/data_folder/project_data.csv csv-data/
    #     else
    #       echo "File does not exist"
    #       echo "Creating project_data.csv"
    #       echo "Your data" > csv-data/project_data.csv  # Create your data file locally
    #       # aws s3 cp csv-data/project_data.csv s3://imagereportbucket/data_folder/  # Upload the file to S3
    #     fi
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.11.3

    - name: Run Python script for version tags/dates
      run: |
        pip install requests
        chmod +x Python_scripts/main.py
        python Python_scripts/main.py  # Replace with the actual name of your Python script
        
    
    - name: Get Dictionary from first Python Script
      id: python-script
      run: |
        # Run the Python script and capture its output
        output=$(python Python_scripts/version_tags_and_dates_flow.py)
        echo "::set-output name=version_dict::$output"
      shell: bash

    # - name: Run Python script
    #   run: |
    #    pip install requests
    #    chmod +x Python_scripts/python_main.py
    #    python Python_scripts/python_main.py  # Replace with the actual name of your Python script


    # - name: Upload Trivy Reports to Amazon S3
    #   run: |
    #     # Define the S3 bucket and folder (prefix) where you want to upload the reports
    #     s3_bucket="imagereportbucket"
    #     current_date=$(date +'%Y-%m-%d')
    #     # Define the S3 prefix, including the current date
    #     s3_prefix="trivy-reports-${current_date}/"
  
    #     # Loop through the reports and upload them to S3
    #     for report in trivy-reports/*.json; do
    #       aws s3 cp "$report" "s3://$s3_bucket/$s3_prefix$(basename $report)"
    #       aws s3 cp csv-data/project_data.csv s3://imagereportbucket/data_folder/  # Upload the file to S3
    #     done
    #   shell: bash
      